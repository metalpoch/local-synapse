# Local Synapse 

**Local Synapse** es un proxy ligero escrito en Go dise帽ado para conectar un servidor local de [Ollama](https://ollama.com/) con el mundo exterior. 

Actualmente, el proyecto se encuentra en una fase pre-MVP, sirviendo como una herramienta de validaci贸n para asegurar que el servidor local es accesible de forma segura y eficiente desde redes externas.

##  Estado Actual

Hoy en d铆a, Local Synapse act煤a como un proxy robusto para la API de Chat de Ollama, ofreciendo:
- **Streaming de alta fidelidad**: Soporte para respuestas largas mediante un b煤fer optimizado de 1MB.
- **Eficiencia de recursos**: Cancelaci贸n autom谩tica de peticiones a Ollama si el cliente se desconecta.
- **Configuraci贸n simple**: Configurable mediante variables de entorno (`PORT`, `OLLAMA_URL`, `SYSTEM_PROMPT`).

##  Instalaci贸n y Uso

### Prerrequisitos
- Go 1.25+
- Ollama corriendo localmente.

### Ejecuci贸n
1. Clona el repositorio.
2. Ejecuta el servidor:
   ```bash
   go run main.go
   ```
3. Realiza una petici贸n de prueba:
   ```bash
   curl "http://localhost:8080/chat?prompt=Hola"
   ```

##  Visi贸n a Futuro

Este proyecto no se detendr谩 en ser un simple proxy. El objetivo es evolucionar hacia una plataforma integrada que permita:

1.  **Gesti贸n de Proyectos Electr贸nicos**: Una interfaz para visualizar datos de sensores, controlar actuadores y organizar esquem谩ticos/documentaci贸n t茅cnica de mis proyectos.
2.  **Asistente LLM Gen茅rico**: Un compa帽ero de IA personalizado que no solo responda preguntas, sino que entienda el contexto de mis desarrollos locales.
4.  **Integraci贸n con MCP (Model Context Protocol)**: Actuar como un host o cliente MCP para permitir que el LLM interact煤e din谩micamente con herramientas externas y bases de conocimiento.
5.  **Frontend Interactivo**: Un panel de control moderno para visualizar el estado de los proyectos electr贸nicos y chatear con los modelos de forma fluida.
6.  **Puente Hardware-IA**: Utilizar la potencia de los LLMs locales para analizar telemetr铆a de hardware en tiempo real.

---
*Desarrollado con わ por poch.*
